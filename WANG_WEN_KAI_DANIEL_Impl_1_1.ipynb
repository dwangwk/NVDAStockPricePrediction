{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8d1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This program uses an LSTM to predict the closing stock price of NVDA using the past 50 trading \n",
    "#day stock prices of NVDA and INTC\n",
    "#Included stock price of INTC as its a similar stock\n",
    "#Main objective was to learn how to create a Many to Many Model and understand how to\n",
    "#input multiple timesteps and features\n",
    "#I understand that the way I created my dataset isn't good as by just\n",
    "#slicing 10 years of data into timesteps of 50, it only creates 55 samples which is insufficient\n",
    "#Have also learned that creating the dataset is the most difficult part \n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab690ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  3.515   ,  23.9     ],\n",
       "        [  3.455   ,  23.85    ],\n",
       "        [  3.6625  ,  24.200001],\n",
       "        ...,\n",
       "        [  3.62    ,  25.59    ],\n",
       "        [  3.5475  ,  25.799999],\n",
       "        [  3.525   ,  25.75    ]],\n",
       "\n",
       "       [[  3.4325  ,  25.139999],\n",
       "        [  3.38    ,  25.040001],\n",
       "        [  3.495   ,  25.389999],\n",
       "        ...,\n",
       "        [  3.61    ,  27.9     ],\n",
       "        [  3.6375  ,  27.879999],\n",
       "        [  3.68    ,  28.190001]],\n",
       "\n",
       "       [[  3.705   ,  28.190001],\n",
       "        [  3.79    ,  27.799999],\n",
       "        [  3.8075  ,  28.16    ],\n",
       "        ...,\n",
       "        [  2.9325  ,  25.040001],\n",
       "        [  3.0175  ,  25.43    ],\n",
       "        [  3.0975  ,  26.07    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[237.139999,  47.93    ],\n",
       "        [229.360001,  48.07    ],\n",
       "        [213.520004,  47.68    ],\n",
       "        ...,\n",
       "        [175.949997,  44.009998],\n",
       "        [166.300003,  42.830002],\n",
       "        [161.75    ,  42.84    ]],\n",
       "\n",
       "       [[177.059998,  43.599998],\n",
       "        [172.639999,  43.080002],\n",
       "        [181.770004,  44.400002],\n",
       "        ...,\n",
       "        [173.190002,  39.200001],\n",
       "        [170.240005,  39.16    ],\n",
       "        [165.330002,  38.959999]],\n",
       "\n",
       "       [[177.899994,  40.18    ],\n",
       "        [179.839996,  39.709999],\n",
       "        [181.630005,  36.310001],\n",
       "        ...,\n",
       "        [125.120003,  26.969999],\n",
       "        [131.669998,  27.700001],\n",
       "        [132.089996,  27.639999]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('NVDA2011to2022.csv')\n",
    "#df = df.filter(items = ['NVDA', 'INTC'] ) # REMOVE DATE\n",
    "X = df.iloc[:2750 , :]  #set training_dataset to multiple of 50\n",
    "X = X.filter(items = ['NVDA', 'INTC'] ) # REMOVE DATE\n",
    "X = np.array(X).reshape(55, 50, 2) #reshape into 55 samples, 50 time steps each, 2 features\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8091ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  3.38    ],\n",
       "        [  3.495   ],\n",
       "        [  3.5875  ],\n",
       "        [  3.555   ],\n",
       "        [  3.6525  ],\n",
       "        [  3.735   ],\n",
       "        [  3.7125  ],\n",
       "        [  3.6775  ],\n",
       "        [  3.7275  ],\n",
       "        [  3.7     ]],\n",
       "\n",
       "       [[  3.79    ],\n",
       "        [  3.8075  ],\n",
       "        [  3.85    ],\n",
       "        [  3.8325  ],\n",
       "        [  3.77    ],\n",
       "        [  3.6625  ],\n",
       "        [  3.6575  ],\n",
       "        [  3.61    ],\n",
       "        [  3.54    ],\n",
       "        [  3.585   ]],\n",
       "\n",
       "       [[  3.03    ],\n",
       "        [  3.065   ],\n",
       "        [  3.1275  ],\n",
       "        [  3.045   ],\n",
       "        [  3.0075  ],\n",
       "        [  3.0725  ],\n",
       "        [  3.1     ],\n",
       "        [  3.31    ],\n",
       "        [  3.3625  ],\n",
       "        [  3.21    ]],\n",
       "\n",
       "       [[  3.6625  ],\n",
       "        [  3.6525  ],\n",
       "        [  3.66    ],\n",
       "        [  3.5775  ],\n",
       "        [  3.65    ],\n",
       "        [  3.5875  ],\n",
       "        [  3.5725  ],\n",
       "        [  3.58    ],\n",
       "        [  3.5125  ],\n",
       "        [  3.5075  ]],\n",
       "\n",
       "       [[  3.1375  ],\n",
       "        [  3.1225  ],\n",
       "        [  3.255   ],\n",
       "        [  3.2525  ],\n",
       "        [  3.1525  ],\n",
       "        [  3.17    ],\n",
       "        [  3.0475  ],\n",
       "        [  2.98    ],\n",
       "        [  2.9575  ],\n",
       "        [  2.885   ]],\n",
       "\n",
       "       [[  2.995   ],\n",
       "        [  3.0225  ],\n",
       "        [  3.0625  ],\n",
       "        [  3.0425  ],\n",
       "        [  3.0275  ],\n",
       "        [  3.0325  ],\n",
       "        [  3.0475  ],\n",
       "        [  3.1025  ],\n",
       "        [  3.1525  ],\n",
       "        [  3.085   ]],\n",
       "\n",
       "       [[  3.2075  ],\n",
       "        [  3.1025  ],\n",
       "        [  3.07    ],\n",
       "        [  3.0325  ],\n",
       "        [  3.0625  ],\n",
       "        [  3.115   ],\n",
       "        [  3.1075  ],\n",
       "        [  3.1575  ],\n",
       "        [  3.2075  ],\n",
       "        [  3.1925  ]],\n",
       "\n",
       "       [[  3.61    ],\n",
       "        [  3.5425  ],\n",
       "        [  3.5125  ],\n",
       "        [  3.5925  ],\n",
       "        [  3.5875  ],\n",
       "        [  3.6225  ],\n",
       "        [  3.6     ],\n",
       "        [  3.71    ],\n",
       "        [  3.61    ],\n",
       "        [  3.605   ]],\n",
       "\n",
       "       [[  3.7375  ],\n",
       "        [  3.72    ],\n",
       "        [  3.74    ],\n",
       "        [  3.74    ],\n",
       "        [  3.7475  ],\n",
       "        [  3.7     ],\n",
       "        [  3.7     ],\n",
       "        [  3.6925  ],\n",
       "        [  3.6875  ],\n",
       "        [  3.69    ]],\n",
       "\n",
       "       [[  3.805   ],\n",
       "        [  3.7975  ],\n",
       "        [  3.815   ],\n",
       "        [  3.705   ],\n",
       "        [  3.7     ],\n",
       "        [  3.725   ],\n",
       "        [  3.6375  ],\n",
       "        [  3.89    ],\n",
       "        [  3.9225  ],\n",
       "        [  3.93    ]],\n",
       "\n",
       "       [[  3.84    ],\n",
       "        [  3.96    ],\n",
       "        [  4.0025  ],\n",
       "        [  4.015   ],\n",
       "        [  3.9975  ],\n",
       "        [  4.0125  ],\n",
       "        [  4.0075  ],\n",
       "        [  3.9925  ],\n",
       "        [  3.89    ],\n",
       "        [  3.865   ]],\n",
       "\n",
       "       [[  4.5075  ],\n",
       "        [  4.4475  ],\n",
       "        [  4.475   ],\n",
       "        [  4.4775  ],\n",
       "        [  4.6625  ],\n",
       "        [  4.6325  ],\n",
       "        [  4.6825  ],\n",
       "        [  4.5375  ],\n",
       "        [  4.5525  ],\n",
       "        [  4.715   ]],\n",
       "\n",
       "       [[  4.7575  ],\n",
       "        [  4.7625  ],\n",
       "        [  4.7875  ],\n",
       "        [  4.85    ],\n",
       "        [  4.88    ],\n",
       "        [  4.885   ],\n",
       "        [  4.87    ],\n",
       "        [  4.9025  ],\n",
       "        [  4.8975  ],\n",
       "        [  4.785   ]],\n",
       "\n",
       "       [[  4.825   ],\n",
       "        [  4.8425  ],\n",
       "        [  4.8125  ],\n",
       "        [  4.7675  ],\n",
       "        [  4.77    ],\n",
       "        [  4.7775  ],\n",
       "        [  4.8625  ],\n",
       "        [  4.8075  ],\n",
       "        [  4.8475  ],\n",
       "        [  4.8625  ]],\n",
       "\n",
       "       [[  4.7325  ],\n",
       "        [  4.7025  ],\n",
       "        [  4.6725  ],\n",
       "        [  4.885   ],\n",
       "        [  4.9675  ],\n",
       "        [  5.0325  ],\n",
       "        [  5.0325  ],\n",
       "        [  5.055   ],\n",
       "        [  4.9475  ],\n",
       "        [  5.005   ]],\n",
       "\n",
       "       [[  4.985   ],\n",
       "        [  4.9225  ],\n",
       "        [  4.915   ],\n",
       "        [  4.935   ],\n",
       "        [  4.9     ],\n",
       "        [  4.99    ],\n",
       "        [  5.005   ],\n",
       "        [  5.075   ],\n",
       "        [  5.1625  ],\n",
       "        [  5.1775  ]],\n",
       "\n",
       "       [[  5.6     ],\n",
       "        [  5.26    ],\n",
       "        [  5.2425  ],\n",
       "        [  5.345   ],\n",
       "        [  5.3675  ],\n",
       "        [  5.2325  ],\n",
       "        [  5.2525  ],\n",
       "        [  5.265   ],\n",
       "        [  5.4175  ],\n",
       "        [  5.465   ]],\n",
       "\n",
       "       [[  5.5225  ],\n",
       "        [  5.565   ],\n",
       "        [  5.4375  ],\n",
       "        [  5.465   ],\n",
       "        [  5.3675  ],\n",
       "        [  5.425   ],\n",
       "        [  5.2775  ],\n",
       "        [  5.2675  ],\n",
       "        [  5.3325  ],\n",
       "        [  5.395   ]],\n",
       "\n",
       "       [[  5.885   ],\n",
       "        [  5.8475  ],\n",
       "        [  5.77    ],\n",
       "        [  5.7475  ],\n",
       "        [  5.54    ],\n",
       "        [  5.3675  ],\n",
       "        [  5.1775  ],\n",
       "        [  5.07    ],\n",
       "        [  5.4525  ],\n",
       "        [  5.6575  ]],\n",
       "\n",
       "       [[  7.115   ],\n",
       "        [  7.11    ],\n",
       "        [  7.1675  ],\n",
       "        [  6.92    ],\n",
       "        [  7.0925  ],\n",
       "        [  7.175   ],\n",
       "        [  7.125   ],\n",
       "        [  7.0075  ],\n",
       "        [  6.9275  ],\n",
       "        [  7.8875  ]],\n",
       "\n",
       "       [[  7.57    ],\n",
       "        [  7.4075  ],\n",
       "        [  7.42    ],\n",
       "        [  7.545   ],\n",
       "        [  7.315   ],\n",
       "        [  7.1675  ],\n",
       "        [  6.7775  ],\n",
       "        [  6.8325  ],\n",
       "        [  6.87    ],\n",
       "        [  6.95    ]],\n",
       "\n",
       "       [[  8.4775  ],\n",
       "        [  8.4625  ],\n",
       "        [  8.6075  ],\n",
       "        [  8.62    ],\n",
       "        [  8.7075  ],\n",
       "        [  8.8475  ],\n",
       "        [  8.94    ],\n",
       "        [  8.9075  ],\n",
       "        [  9.0375  ],\n",
       "        [  8.95    ]],\n",
       "\n",
       "       [[ 11.7025  ],\n",
       "        [ 11.785   ],\n",
       "        [ 11.62    ],\n",
       "        [ 11.56    ],\n",
       "        [ 11.5825  ],\n",
       "        [ 11.545   ],\n",
       "        [ 11.845   ],\n",
       "        [ 11.55    ],\n",
       "        [ 11.6975  ],\n",
       "        [ 11.72    ]],\n",
       "\n",
       "       [[ 14.925   ],\n",
       "        [ 15.76    ],\n",
       "        [ 15.745   ],\n",
       "        [ 15.65    ],\n",
       "        [ 15.2875  ],\n",
       "        [ 15.525   ],\n",
       "        [ 15.565   ],\n",
       "        [ 15.63    ],\n",
       "        [ 15.7275  ],\n",
       "        [ 15.485   ]],\n",
       "\n",
       "       [[ 16.885   ],\n",
       "        [ 17.6775  ],\n",
       "        [ 17.967501],\n",
       "        [ 18.040001],\n",
       "        [ 17.67    ],\n",
       "        [ 17.639999],\n",
       "        [ 17.790001],\n",
       "        [ 17.262501],\n",
       "        [ 17.190001],\n",
       "        [ 16.99    ]],\n",
       "\n",
       "       [[ 26.0975  ],\n",
       "        [ 25.434999],\n",
       "        [ 25.775   ],\n",
       "        [ 26.82    ],\n",
       "        [ 26.6175  ],\n",
       "        [ 26.290001],\n",
       "        [ 25.860001],\n",
       "        [ 25.8575  ],\n",
       "        [ 25.2775  ],\n",
       "        [ 25.737499]],\n",
       "\n",
       "       [[ 26.5175  ],\n",
       "        [ 27.362499],\n",
       "        [ 26.477501],\n",
       "        [ 27.0175  ],\n",
       "        [ 26.772499],\n",
       "        [ 26.8675  ],\n",
       "        [ 27.0625  ],\n",
       "        [ 26.922501],\n",
       "        [ 26.834999],\n",
       "        [ 27.35    ]],\n",
       "\n",
       "       [[ 36.217499],\n",
       "        [ 36.087502],\n",
       "        [ 36.09    ],\n",
       "        [ 35.91    ],\n",
       "        [ 37.002499],\n",
       "        [ 36.834999],\n",
       "        [ 37.279999],\n",
       "        [ 39.985001],\n",
       "        [ 37.400002],\n",
       "        [ 37.4925  ]],\n",
       "\n",
       "       [[ 43.0275  ],\n",
       "        [ 41.185001],\n",
       "        [ 38.990002],\n",
       "        [ 42.099998],\n",
       "        [ 41.744999],\n",
       "        [ 41.287498],\n",
       "        [ 40.3675  ],\n",
       "        [ 40.375   ],\n",
       "        [ 39.787498],\n",
       "        [ 40.637501]],\n",
       "\n",
       "       [[ 49.450001],\n",
       "        [ 49.224998],\n",
       "        [ 49.154999],\n",
       "        [ 49.669998],\n",
       "        [ 48.415001],\n",
       "        [ 48.922501],\n",
       "        [ 50.465   ],\n",
       "        [ 50.959999],\n",
       "        [ 51.702499],\n",
       "        [ 51.799999]],\n",
       "\n",
       "       [[ 49.837502],\n",
       "        [ 53.1175  ],\n",
       "        [ 53.397499],\n",
       "        [ 53.849998],\n",
       "        [ 55.5     ],\n",
       "        [ 55.485001],\n",
       "        [ 55.919998],\n",
       "        [ 56.02    ],\n",
       "        [ 55.744999],\n",
       "        [ 55.0275  ]],\n",
       "\n",
       "       [[ 62.334999],\n",
       "        [ 62.619999],\n",
       "        [ 60.25    ],\n",
       "        [ 62.395   ],\n",
       "        [ 62.139999],\n",
       "        [ 60.462502],\n",
       "        [ 58.2425  ],\n",
       "        [ 61.119999],\n",
       "        [ 56.380001],\n",
       "        [ 55.337502]],\n",
       "\n",
       "       [[ 62.32    ],\n",
       "        [ 62.147499],\n",
       "        [ 63.247501],\n",
       "        [ 63.047501],\n",
       "        [ 64.404999],\n",
       "        [ 66.212502],\n",
       "        [ 66.267502],\n",
       "        [ 66.287498],\n",
       "        [ 65.724998],\n",
       "        [ 65.57    ]],\n",
       "\n",
       "       [[ 64.237503],\n",
       "        [ 64.605003],\n",
       "        [ 64.114998],\n",
       "        [ 63.697498],\n",
       "        [ 64.029999],\n",
       "        [ 65.357498],\n",
       "        [ 64.769997],\n",
       "        [ 64.360001],\n",
       "        [ 61.205002],\n",
       "        [ 61.959999]],\n",
       "\n",
       "       [[ 60.764999],\n",
       "        [ 59.8825  ],\n",
       "        [ 57.2925  ],\n",
       "        [ 57.805   ],\n",
       "        [ 55.264999],\n",
       "        [ 49.852501],\n",
       "        [ 51.959999],\n",
       "        [ 49.572498],\n",
       "        [ 46.404999],\n",
       "        [ 50.75    ]],\n",
       "\n",
       "       [[ 33.375   ],\n",
       "        [ 34.055   ],\n",
       "        [ 31.997499],\n",
       "        [ 34.047501],\n",
       "        [ 35.849998],\n",
       "        [ 34.9575  ],\n",
       "        [ 35.645   ],\n",
       "        [ 36.307499],\n",
       "        [ 37.2075  ],\n",
       "        [ 37.610001]],\n",
       "\n",
       "       [[ 41.389999],\n",
       "        [ 42.452499],\n",
       "        [ 42.237499],\n",
       "        [ 43.927502],\n",
       "        [ 43.599998],\n",
       "        [ 45.985001],\n",
       "        [ 44.375   ],\n",
       "        [ 43.445   ],\n",
       "        [ 44.217499],\n",
       "        [ 44.125   ]],\n",
       "\n",
       "       [[ 36.287498],\n",
       "        [ 35.8325  ],\n",
       "        [ 35.084999],\n",
       "        [ 34.7775  ],\n",
       "        [ 33.865002],\n",
       "        [ 33.445   ],\n",
       "        [ 35.75    ],\n",
       "        [ 35.32    ],\n",
       "        [ 35.945   ],\n",
       "        [ 36.375   ]],\n",
       "\n",
       "       [[ 38.087502],\n",
       "        [ 38.4725  ],\n",
       "        [ 39.564999],\n",
       "        [ 38.544998],\n",
       "        [ 37.862499],\n",
       "        [ 39.012501],\n",
       "        [ 37.517502],\n",
       "        [ 37.192501],\n",
       "        [ 39.889999],\n",
       "        [ 42.695   ]],\n",
       "\n",
       "       [[ 48.552502],\n",
       "        [ 48.572498],\n",
       "        [ 47.622501],\n",
       "        [ 49.002499],\n",
       "        [ 48.9025  ],\n",
       "        [ 48.772499],\n",
       "        [ 49.215   ],\n",
       "        [ 51.134998],\n",
       "        [ 51.697498],\n",
       "        [ 50.73    ]],\n",
       "\n",
       "       [[ 59.217499],\n",
       "        [ 58.080002],\n",
       "        [ 58.825001],\n",
       "        [ 59.977501],\n",
       "        [ 59.017502],\n",
       "        [ 59.264999],\n",
       "        [ 59.982498],\n",
       "        [ 60.095001],\n",
       "        [ 60.755001],\n",
       "        [ 61.080002]],\n",
       "\n",
       "       [[ 61.6175  ],\n",
       "        [ 54.077499],\n",
       "        [ 60.209999],\n",
       "        [ 49.099998],\n",
       "        [ 54.317501],\n",
       "        [ 50.705002],\n",
       "        [ 53.2425  ],\n",
       "        [ 51.4375  ],\n",
       "        [ 53.172501],\n",
       "        [ 62.294998]],\n",
       "\n",
       "       [[ 87.752502],\n",
       "        [ 90.262497],\n",
       "        [ 87.177498],\n",
       "        [ 85.252502],\n",
       "        [ 84.870003],\n",
       "        [ 88.754997],\n",
       "        [ 88.0625  ],\n",
       "        [ 88.252502],\n",
       "        [ 87.695   ],\n",
       "        [ 87.665001]],\n",
       "\n",
       "       [[110.102501],\n",
       "        [112.277496],\n",
       "        [112.8675  ],\n",
       "        [113.355003],\n",
       "        [111.995003],\n",
       "        [111.650002],\n",
       "        [108.5     ],\n",
       "        [114.402496],\n",
       "        [114.43    ],\n",
       "        [115.639999]],\n",
       "\n",
       "       [[142.482498],\n",
       "        [140.952499],\n",
       "        [139.699997],\n",
       "        [138.115005],\n",
       "        [134.977493],\n",
       "        [136.455002],\n",
       "        [135.247498],\n",
       "        [133.610001],\n",
       "        [135.902496],\n",
       "        [131.412506]],\n",
       "\n",
       "       [[130.092499],\n",
       "        [129.9375  ],\n",
       "        [129.      ],\n",
       "        [129.432495],\n",
       "        [131.457504],\n",
       "        [130.550003],\n",
       "        [131.134995],\n",
       "        [134.047501],\n",
       "        [126.144997],\n",
       "        [133.440002]],\n",
       "\n",
       "       [[125.202499],\n",
       "        [124.682503],\n",
       "        [129.934998],\n",
       "        [128.559998],\n",
       "        [131.912506],\n",
       "        [132.912506],\n",
       "        [133.412506],\n",
       "        [127.224998],\n",
       "        [128.457504],\n",
       "        [131.862503]],\n",
       "\n",
       "       [[140.657501],\n",
       "        [146.125   ],\n",
       "        [149.917496],\n",
       "        [156.119995],\n",
       "        [156.477493],\n",
       "        [157.      ],\n",
       "        [154.880005],\n",
       "        [162.445007],\n",
       "        [162.645004],\n",
       "        [167.782501]],\n",
       "\n",
       "       [[194.990005],\n",
       "        [197.5     ],\n",
       "        [198.149994],\n",
       "        [202.740005],\n",
       "        [206.369995],\n",
       "        [203.660004],\n",
       "        [202.949997],\n",
       "        [199.360001],\n",
       "        [196.990005],\n",
       "        [199.050003]],\n",
       "\n",
       "       [[206.949997],\n",
       "        [206.710007],\n",
       "        [209.389999],\n",
       "        [217.460007],\n",
       "        [218.619995],\n",
       "        [222.220001],\n",
       "        [222.899994],\n",
       "        [221.029999],\n",
       "        [226.919998],\n",
       "        [227.259995]],\n",
       "\n",
       "       [[290.75    ],\n",
       "        [294.      ],\n",
       "        [296.399994],\n",
       "        [309.450012],\n",
       "        [303.220001],\n",
       "        [300.01001 ],\n",
       "        [295.859985],\n",
       "        [294.109985],\n",
       "        [301.209991],\n",
       "        [292.899994]],\n",
       "\n",
       "       [[229.360001],\n",
       "        [213.520004],\n",
       "        [215.139999],\n",
       "        [230.139999],\n",
       "        [226.580002],\n",
       "        [221.      ],\n",
       "        [213.300003],\n",
       "        [229.729996],\n",
       "        [244.960007],\n",
       "        [247.660004]],\n",
       "\n",
       "       [[172.639999],\n",
       "        [181.770004],\n",
       "        [169.380005],\n",
       "        [171.240005],\n",
       "        [166.940002],\n",
       "        [168.979996],\n",
       "        [161.539993],\n",
       "        [169.75    ],\n",
       "        [178.509995],\n",
       "        [188.110001]],\n",
       "\n",
       "       [[179.839996],\n",
       "        [181.630005],\n",
       "        [184.410004],\n",
       "        [185.259995],\n",
       "        [188.929993],\n",
       "        [192.149994],\n",
       "        [189.889999],\n",
       "        [177.929993],\n",
       "        [170.860001],\n",
       "        [180.970001]],\n",
       "\n",
       "       [[120.760002],\n",
       "        [116.699997],\n",
       "        [115.860001],\n",
       "        [115.      ],\n",
       "        [119.599998],\n",
       "        [112.269997],\n",
       "        [118.879997],\n",
       "        [119.669998],\n",
       "        [120.510002],\n",
       "        [121.940002]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = [] #creating the prediction output which is the subsequent 10 trading days (2 weeks)\n",
    "df_Y = df.filter(items = ['NVDA'] )\n",
    "for i in range(50, 2760): #obtains the next 10 trading days after the first 50\n",
    "    if i % 50 < 10:\n",
    "        Y.append(df_Y[i+1:i+2])\n",
    "Y = np.array(Y).reshape(55,10,1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d3bd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 2s 78ms/step - loss: 2876.8857 - val_loss: 61860.3984\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2810.5588 - val_loss: 36587.7812\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 28871.3066 - val_loss: 47852.0117\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5104.0889 - val_loss: 32636.4492\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3129.2048 - val_loss: 36599.3398\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5462.8335 - val_loss: 77026.6172\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1893.2859 - val_loss: 17585.1992\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2513.2468 - val_loss: 22873.8164\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1881.7793 - val_loss: 50431.3750\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3943.7412 - val_loss: 317759.9688\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 25875.3008 - val_loss: 288895.7188\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 149046.6406 - val_loss: 39949.2969\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 16964.2969 - val_loss: 52441.7227\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 25833.0918 - val_loss: 16860.5195\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15411.0596 - val_loss: 75285.5938\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7977.3809 - val_loss: 36265.5352\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4058.3015 - val_loss: 54508.5508\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6026.7612 - val_loss: 914139.0625\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14530.9531 - val_loss: 771510.4375\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 12267.7031 - val_loss: 516565.7188\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15615.9346 - val_loss: 226746.1094\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5275.3159 - val_loss: 166218.0625\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2641.7712 - val_loss: 93684.7266\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3982.9944 - val_loss: 90324.4531\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2829.0659 - val_loss: 175335.9375\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2657.4651 - val_loss: 57146.2539\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9140.5654 - val_loss: 40393.6875\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4352.4526 - val_loss: 84216.4375\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1659.2449 - val_loss: 88310.8281\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2555.1130 - val_loss: 404377.4688\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1804.6609 - val_loss: 946531.0625\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1343.3054 - val_loss: 688963.1875\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1540.2324 - val_loss: 310700.9375\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8890.3369 - val_loss: 1209055.5000\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8449.0752 - val_loss: 79594.0703\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1317.9512 - val_loss: 59603.7773\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5021.3516 - val_loss: 141520.2969\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 6636.2339 - val_loss: 237649.2656\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 11738.6729 - val_loss: 112116.2969\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8903.7949 - val_loss: 197311.9375\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10566.9014 - val_loss: 361070.5938\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9913.5303 - val_loss: 161667.1719\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 10023.1055 - val_loss: 188479.4062\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 18193.0957 - val_loss: 365199.2188\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 15164.1973 - val_loss: 314242.4375\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 12694.5664 - val_loss: 216801.9062\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 14924.8066 - val_loss: 345736.0000\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 13518.7197 - val_loss: 230684.6875\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3468.7476 - val_loss: 60974.2109\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10293.6230 - val_loss: 58080.7969\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4836.4097 - val_loss: 87317.4531\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4799.3003 - val_loss: 75712.2656\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2649.6448 - val_loss: 88489.3750\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2320.6743 - val_loss: 102049.6250\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1007.5226 - val_loss: 115117.0234\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 648.7726 - val_loss: 82719.3047\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 637.3645 - val_loss: 106018.9766\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 588.0256 - val_loss: 91344.9219\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 959.9667 - val_loss: 110320.1016\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 350.3208 - val_loss: 81391.9297\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 385.4495 - val_loss: 79794.4453\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 443.0237 - val_loss: 79274.1328\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 339.5243 - val_loss: 47831.8711\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 295.9240 - val_loss: 76906.1641\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 294.3230 - val_loss: 38367.0938\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 245.0437 - val_loss: 48917.1875\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 224.6667 - val_loss: 43713.6523\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 251.8793 - val_loss: 37815.6445\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 229.4123 - val_loss: 73790.3359\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1286.6239 - val_loss: 39379.6367\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 363.5909 - val_loss: 35939.4492\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 256.5943 - val_loss: 65467.8594\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 361.3779 - val_loss: 34736.8398\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 212.1022 - val_loss: 34547.2266\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 214.1389 - val_loss: 29857.8867\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 231.2610 - val_loss: 26854.4609\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 214.4216 - val_loss: 26756.4180\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step - loss: 207.1237 - val_loss: 26445.5391\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 176.1926 - val_loss: 27408.0488\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 183.8315 - val_loss: 26903.7188\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 175.5394 - val_loss: 25591.9492\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 191.4187 - val_loss: 25556.4004\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 192.7843 - val_loss: 26506.1641\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 171.2901 - val_loss: 26674.7754\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 156.7158 - val_loss: 27274.2988\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 164.7640 - val_loss: 27581.0254\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 164.9201 - val_loss: 27198.2363\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 155.6996 - val_loss: 25818.4824\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 148.2828 - val_loss: 25392.2363\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 143.5290 - val_loss: 25413.9766\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 144.0714 - val_loss: 25405.8047\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 142.5247 - val_loss: 26852.8242\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 140.9285 - val_loss: 28189.8105\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 145.9149 - val_loss: 28382.1562\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 149.7330 - val_loss: 26297.5293\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 130.9399 - val_loss: 26638.4316\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 146.9384 - val_loss: 26805.3125\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 141.5820 - val_loss: 26449.9375\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 182.3143 - val_loss: 26467.5625\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 169.2483 - val_loss: 42782.8984\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 156.7472 - val_loss: 41849.5859\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 136.6321 - val_loss: 41782.5508\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 129.1775 - val_loss: 42557.7578\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 122.3808 - val_loss: 43073.9219\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 110.8791 - val_loss: 41125.8281\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 106.3616 - val_loss: 38520.1172\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 121.6302 - val_loss: 36393.9531\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 121.9690 - val_loss: 36360.3398\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 110.2173 - val_loss: 36319.8906\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 104.7644 - val_loss: 35310.3789\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 97.9749 - val_loss: 34850.9531\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 92.2237 - val_loss: 35245.2383\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 83.5978 - val_loss: 35263.8672\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 82.3207 - val_loss: 35249.1602\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 80.5314 - val_loss: 35307.9844\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 80.0397 - val_loss: 35413.4062\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 78.6449 - val_loss: 35500.1836\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 76.9861 - val_loss: 35483.3711\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 77.3477 - val_loss: 35482.8320\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 76.3702 - val_loss: 35349.2031\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 76.1096 - val_loss: 35322.2070\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 74.3205 - val_loss: 35388.2148\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73.6654 - val_loss: 35404.3945\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73.4402 - val_loss: 35344.5820\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73.5873 - val_loss: 35248.9609\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 81.4957 - val_loss: 34857.7070\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 76.9114 - val_loss: 34828.9570\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 78.7076 - val_loss: 34913.6680\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 79.7204 - val_loss: 34589.6914\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 77.7703 - val_loss: 34927.1719\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 75.4566 - val_loss: 34788.1289\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 76.3238 - val_loss: 34797.1094\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 75.4579 - val_loss: 34814.3984\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 74.0925 - val_loss: 34938.3281\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 74.5477 - val_loss: 35035.2734\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73.0460 - val_loss: 34864.8984\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 73.5664 - val_loss: 34546.3828\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 72.8508 - val_loss: 34550.5508\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 69.1880 - val_loss: 34498.8906\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 68.8104 - val_loss: 34254.5898\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 65.0500 - val_loss: 33884.9609\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 70.7128 - val_loss: 33899.7656\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 65.4317 - val_loss: 34072.1406\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 70.3463 - val_loss: 33826.3672\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 71.3548 - val_loss: 33288.4766\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 68.1895 - val_loss: 33509.8086\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 67.0592 - val_loss: 33580.0195\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 66.9597 - val_loss: 33443.9219\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 66.6622 - val_loss: 33417.1016\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 65.0668 - val_loss: 33388.5156\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65.4135 - val_loss: 33474.2031\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 66.8807 - val_loss: 34375.2500\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 62.8499 - val_loss: 34413.4062\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 64.5968 - val_loss: 34475.4727\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65.9310 - val_loss: 34432.2656\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step - loss: 63.2527 - val_loss: 34060.9141\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 63.2017 - val_loss: 34450.0234\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61.7881 - val_loss: 34343.6211\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61.1854 - val_loss: 34629.1172\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60.7925 - val_loss: 34625.1719\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60.7033 - val_loss: 34475.4141\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61.9885 - val_loss: 34697.0703\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 59.3408 - val_loss: 34478.1641\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 59.0687 - val_loss: 34228.4297\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 60.2058 - val_loss: 34537.1914\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 59.5317 - val_loss: 34718.2461\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57.9782 - val_loss: 34760.7344\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 58.3494 - val_loss: 34858.4570\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57.7405 - val_loss: 34857.1211\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57.9822 - val_loss: 34716.6016\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56.3312 - val_loss: 34536.4336\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 59.5563 - val_loss: 34836.6484\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57.8408 - val_loss: 34752.1250\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60.2814 - val_loss: 34491.7031\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 58.0740 - val_loss: 34849.9336\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56.9810 - val_loss: 34535.3945\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.5545 - val_loss: 34524.4766\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.3794 - val_loss: 34613.2031\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.0161 - val_loss: 35069.5469\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 58.2811 - val_loss: 34841.3438\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 54.3309 - val_loss: 35826.9102\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.8897 - val_loss: 36491.2969\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.4616 - val_loss: 36615.3477\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.7761 - val_loss: 35304.5273\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.0764 - val_loss: 36863.2930\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.4328 - val_loss: 36662.8164\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.2521 - val_loss: 36475.4375\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56.0906 - val_loss: 36819.3359\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.9947 - val_loss: 36656.3789\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.1573 - val_loss: 36665.5430\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 54.3977 - val_loss: 36803.1094\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.2122 - val_loss: 37298.7695\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 59.6338 - val_loss: 37235.8086\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 56.6545 - val_loss: 36584.1680\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 59.5829 - val_loss: 36918.1406\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 54.2442 - val_loss: 36977.0039\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.7255 - val_loss: 37311.0977\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.7868 - val_loss: 37777.3086\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61.2210 - val_loss: 37554.9805\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.2656 - val_loss: 38338.6094\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.8526 - val_loss: 38071.1914\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.7811 - val_loss: 37776.3359\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.7041 - val_loss: 37636.8594\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.7117 - val_loss: 38013.9375\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.3367 - val_loss: 37954.2148\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.6783 - val_loss: 37822.4492\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.9781 - val_loss: 37739.9336\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.8553 - val_loss: 38207.8984\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.2281 - val_loss: 37827.4062\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.5511 - val_loss: 37639.2031\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.4422 - val_loss: 37625.0156\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.8650 - val_loss: 37967.6523\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.3525 - val_loss: 37724.9219\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 58.8173 - val_loss: 37380.8906\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.7605 - val_loss: 38592.5781\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.0587 - val_loss: 38115.6484\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.1185 - val_loss: 37372.0781\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.6553 - val_loss: 38501.2617\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51.5232 - val_loss: 38275.9922\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 50.5076 - val_loss: 37579.9258\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.9497 - val_loss: 37846.3398\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.0392 - val_loss: 38056.5781\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.9376 - val_loss: 37914.2969\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47.8388 - val_loss: 37768.0664\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.2386 - val_loss: 37147.5430\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.7295 - val_loss: 37562.6484\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.4065 - val_loss: 37858.6133\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.0451 - val_loss: 37525.7695\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.7428 - val_loss: 37678.6602\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.8077 - val_loss: 37974.2188\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.5884 - val_loss: 37502.6562\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.5052 - val_loss: 37698.3086\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.8147 - val_loss: 38266.9453\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step - loss: 47.9755 - val_loss: 37371.2656\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.9192 - val_loss: 37259.3398\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.0070 - val_loss: 37864.9258\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.7252 - val_loss: 37745.1211\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.1580 - val_loss: 37187.1250\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 61.3115 - val_loss: 37256.9531\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.6897 - val_loss: 38569.8438\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.6464 - val_loss: 37854.5508\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.6233 - val_loss: 36962.0586\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.3726 - val_loss: 37569.1992\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.6615 - val_loss: 38411.4609\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.3956 - val_loss: 37357.8789\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.1154 - val_loss: 36643.4062\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.5518 - val_loss: 37435.3633\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43.9082 - val_loss: 38424.0664\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.3356 - val_loss: 37457.3945\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.9357 - val_loss: 36804.1133\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47.8459 - val_loss: 37701.6172\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.0366 - val_loss: 37763.5586\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.7959 - val_loss: 37176.9492\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.3812 - val_loss: 37646.3906\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.5899 - val_loss: 37306.0586\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.2065 - val_loss: 37184.2031\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.4656 - val_loss: 37333.1914\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.0407 - val_loss: 37691.2969\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.4664 - val_loss: 37465.0156\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.4238 - val_loss: 36740.2617\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.0583 - val_loss: 38037.9141\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.0243 - val_loss: 37462.1289\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 48.9221 - val_loss: 36301.3398\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.0370 - val_loss: 37233.9570\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.3167 - val_loss: 37918.9023\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.8600 - val_loss: 36783.5000\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.4787 - val_loss: 37469.3672\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.8621 - val_loss: 37350.6523\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.0317 - val_loss: 36858.9648\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43.5636 - val_loss: 36962.6406\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.6918 - val_loss: 37156.2852\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.8058 - val_loss: 37085.4531\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.5778 - val_loss: 36850.7539\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.2259 - val_loss: 36342.1172\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.7551 - val_loss: 36864.2500\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.1031 - val_loss: 37005.5430\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43.1651 - val_loss: 36699.4844\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45.3968 - val_loss: 36625.3828\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.1819 - val_loss: 37385.4180\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44.1453 - val_loss: 37181.1953\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 46.1364 - val_loss: 36930.5195\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.2622 - val_loss: 37044.9414\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.2402 - val_loss: 37116.9258\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.1282 - val_loss: 37331.1484\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47.7376 - val_loss: 37753.6445\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.6533 - val_loss: 37131.0586\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 46.6794 - val_loss: 37273.7148\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.8739 - val_loss: 37867.0391\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.0567 - val_loss: 37445.0859\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.4416 - val_loss: 37988.5586\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.4108 - val_loss: 37619.3945\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.9062 - val_loss: 37495.6719\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.2107 - val_loss: 38158.1445\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.9985 - val_loss: 37884.4297\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44.0357 - val_loss: 38029.8828\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.8204 - val_loss: 38194.5508\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.3960 - val_loss: 38261.0586\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 54.3010 - val_loss: 38442.4648\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44.7201 - val_loss: 37384.2031\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.9474 - val_loss: 38600.4727\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43.5371 - val_loss: 38596.3398\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.7942 - val_loss: 37893.7539\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47.2573 - val_loss: 37901.7109\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.9614 - val_loss: 38630.9102\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.9117 - val_loss: 37786.7383\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 47.4616 - val_loss: 37739.1836\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.1331 - val_loss: 38739.1602\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45.7888 - val_loss: 38295.0859\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.7556 - val_loss: 37723.9844\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.0203 - val_loss: 38015.3945\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.8329 - val_loss: 38501.7148\n",
      "Epoch 312/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 20ms/step - loss: 42.2838 - val_loss: 38009.7852\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.3199 - val_loss: 38042.2109\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.6152 - val_loss: 38142.5898\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.0686 - val_loss: 37746.9414\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.2587 - val_loss: 37851.2773\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.1813 - val_loss: 38231.7227\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.3364 - val_loss: 38336.7539\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 45.7081 - val_loss: 38476.5430\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.9487 - val_loss: 38008.3477\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 42.0004 - val_loss: 37464.4102\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 51.7718 - val_loss: 41460.2031\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 40.4263 - val_loss: 38640.1211\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.4762 - val_loss: 38837.3672\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.6048 - val_loss: 38438.1953\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 48.4982 - val_loss: 38308.4062\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.1792 - val_loss: 43912.3164\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.8371 - val_loss: 39141.9453\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 47.7701 - val_loss: 46055.1758\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.8509 - val_loss: 46063.7852\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.5682 - val_loss: 46710.6562\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.0694 - val_loss: 46766.8828\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57.4386 - val_loss: 46066.2227\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.4334 - val_loss: 45384.6211\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 54.3539 - val_loss: 46333.5156\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 57.0037 - val_loss: 45310.1602\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60.0306 - val_loss: 41835.5273\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.5012 - val_loss: 46172.3711\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 52.2044 - val_loss: 46175.5469\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.5997 - val_loss: 46910.6445\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.2535 - val_loss: 46487.8555\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.7407 - val_loss: 45861.9023\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.2730 - val_loss: 46297.1523\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.2046 - val_loss: 46030.6445\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.5882 - val_loss: 46322.7461\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.2246 - val_loss: 46705.0703\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.8084 - val_loss: 46487.7969\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.5264 - val_loss: 46128.7773\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.2910 - val_loss: 46224.5625\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.5896 - val_loss: 46021.0625\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.5292 - val_loss: 45898.6719\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.8755 - val_loss: 46171.3125\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.5548 - val_loss: 46420.6562\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.9028 - val_loss: 46227.0547\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.4805 - val_loss: 46167.0352\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.3002 - val_loss: 46176.5273\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.9924 - val_loss: 45651.8164\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.1508 - val_loss: 46128.0586\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.4742 - val_loss: 46421.7148\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.4667 - val_loss: 45772.8203\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.2937 - val_loss: 45957.5273\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.2527 - val_loss: 46264.6758\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.1048 - val_loss: 46441.3281\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.8842 - val_loss: 45973.3203\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.8578 - val_loss: 46306.2969\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.7070 - val_loss: 45955.8711\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.8966 - val_loss: 45763.5664\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.7490 - val_loss: 46253.0820\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.5149 - val_loss: 46336.1719\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.9427 - val_loss: 45921.0547\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.5534 - val_loss: 45848.6836\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.7415 - val_loss: 46349.8516\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.7910 - val_loss: 46408.0586\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.3467 - val_loss: 45747.2891\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.9546 - val_loss: 46124.2422\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.0868 - val_loss: 46342.0156\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.2024 - val_loss: 45983.4414\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.1213 - val_loss: 45635.4414\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.9911 - val_loss: 46523.3711\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.6283 - val_loss: 46248.6367\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.8102 - val_loss: 45678.1406\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.4421 - val_loss: 46324.0898\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.0229 - val_loss: 46028.4297\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.0915 - val_loss: 45077.4922\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.7687 - val_loss: 45930.0938\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.0554 - val_loss: 46170.7773\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.7666 - val_loss: 46088.8086\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.1250 - val_loss: 46403.8242\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.4788 - val_loss: 46526.1406\n",
      "Epoch 390/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step - loss: 40.0779 - val_loss: 44858.3945\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 65.9165 - val_loss: 45667.4688\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 63.7762 - val_loss: 46744.7227\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 33.8569 - val_loss: 45578.7188\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.2554 - val_loss: 46546.1680\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.0487 - val_loss: 46760.7969\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.3380 - val_loss: 46135.9258\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.6973 - val_loss: 45812.1406\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.0259 - val_loss: 45870.9141\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.8349 - val_loss: 45965.4023\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.4865 - val_loss: 46213.1016\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.8205 - val_loss: 46075.3320\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.2963 - val_loss: 45858.6914\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.5556 - val_loss: 46168.2617\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.6522 - val_loss: 45704.4531\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.7651 - val_loss: 45906.0898\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.9330 - val_loss: 46339.7227\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.3917 - val_loss: 46108.9062\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.9830 - val_loss: 45962.4961\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.1804 - val_loss: 45911.1172\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.1102 - val_loss: 45349.6367\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.6693 - val_loss: 46538.9219\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.1026 - val_loss: 46417.8594\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.0940 - val_loss: 46144.8398\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.2183 - val_loss: 45366.7695\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.6344 - val_loss: 45594.4336\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.0256 - val_loss: 45643.1328\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37.5873 - val_loss: 45986.6250\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.8953 - val_loss: 45515.6523\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.3488 - val_loss: 45684.1328\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.1665 - val_loss: 45908.6602\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.6292 - val_loss: 46133.7188\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.5638 - val_loss: 45798.4570\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.7939 - val_loss: 45668.2695\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.5039 - val_loss: 46267.8750\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.3685 - val_loss: 45406.5820\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.3792 - val_loss: 45788.5273\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.3689 - val_loss: 46886.7852\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.0225 - val_loss: 46066.8438\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.9888 - val_loss: 45605.9414\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.7283 - val_loss: 46542.3398\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.1692 - val_loss: 45549.5977\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.5793 - val_loss: 45390.9336\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 42.2198 - val_loss: 46175.5938\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.5837 - val_loss: 45577.3789\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.5946 - val_loss: 45609.1562\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.2519 - val_loss: 45552.2383\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.1674 - val_loss: 46052.8984\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.7654 - val_loss: 45779.0977\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.7342 - val_loss: 46226.0234\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.1209 - val_loss: 46354.7734\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60.1953 - val_loss: 45740.9102\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.0366 - val_loss: 46103.7695\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.6035 - val_loss: 45930.7969\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.7372 - val_loss: 46286.5117\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 39.1142 - val_loss: 46139.4961\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.3107 - val_loss: 45160.1914\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 43.4270 - val_loss: 45468.3594\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 49.4634 - val_loss: 44997.0977\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 60.6312 - val_loss: 46859.8164\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.0494 - val_loss: 46953.6602\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 51.4216 - val_loss: 46490.1445\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.7365 - val_loss: 46615.2383\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.6893 - val_loss: 46075.7734\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.1391 - val_loss: 45814.0391\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.4011 - val_loss: 47255.0977\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.3115 - val_loss: 46611.9844\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 55.3129 - val_loss: 46728.0312\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.1596 - val_loss: 45938.6211\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 41.9974 - val_loss: 47211.1094\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.5306 - val_loss: 46802.3672\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 53.5620 - val_loss: 46933.4648\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.0585 - val_loss: 46742.6133\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.3813 - val_loss: 46701.6328\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.2891 - val_loss: 46921.8594\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 34.8746 - val_loss: 46208.3086\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 43.3269 - val_loss: 47375.7031\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 42.1887 - val_loss: 47378.3906\n",
      "Epoch 468/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 19ms/step - loss: 43.9834 - val_loss: 48017.3008\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.8124 - val_loss: 47123.9727\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.5893 - val_loss: 46962.6641\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.4797 - val_loss: 47562.7852\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.3256 - val_loss: 47650.3711\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 37.7526 - val_loss: 47189.8867\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.7563 - val_loss: 47514.9102\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.8450 - val_loss: 47128.7422\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.1733 - val_loss: 47487.0273\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 34.6337 - val_loss: 47179.6797\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.8202 - val_loss: 47454.8320\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 50.6323 - val_loss: 46982.3203\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 46.1255 - val_loss: 47104.7852\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 45.2074 - val_loss: 47100.1914\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 40.5903 - val_loss: 47073.6914\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 44.5785 - val_loss: 47156.3477\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.4005 - val_loss: 47576.6211\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37.8418 - val_loss: 47311.8711\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 44.0036 - val_loss: 47191.3789\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 38.3307 - val_loss: 46661.9023\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 41.8545 - val_loss: 47369.2031\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.8108 - val_loss: 46758.6523\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37.1061 - val_loss: 47140.0977\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35.8407 - val_loss: 47444.1758\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 36.9317 - val_loss: 47056.3906\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 35.9704 - val_loss: 46677.3594\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 37.6780 - val_loss: 47047.4141\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.3013 - val_loss: 47497.9531\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 39.1651 - val_loss: 47295.1367\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.2580 - val_loss: 46767.5977\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.0237 - val_loss: 47117.6914\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 36.1602 - val_loss: 47384.7305\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 38.8389 - val_loss: 47249.0898\n"
     ]
    }
   ],
   "source": [
    "#stacked LSTM model\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(50, 2)))\n",
    "model.add(RepeatVector(10))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=500, validation_split=0.2, verbose=1, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae0f25a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[82.207275]\n",
      "  [80.95891 ]\n",
      "  [71.27672 ]\n",
      "  [72.897316]\n",
      "  [75.4754  ]\n",
      "  [76.47345 ]\n",
      "  [74.70563 ]\n",
      "  [72.67723 ]\n",
      "  [70.040115]\n",
      "  [66.75745 ]]]\n"
     ]
    }
   ],
   "source": [
    "#prediction for the next 10 days from 3 Nov\n",
    "test_input = pd.read_csv('NVDATEST.csv')\n",
    "test_input = test_input.filter(items = ['NVDA', 'INTC'] )\n",
    "test_input = np.array(test_input).reshape(1,50,2)\n",
    "test_input\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output) #predicts a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4635c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
